参考

>[https://gitee.com/zc10010/java_interview_guide/tree/master/%E7%9F%A5%E8%AF%86%E7%82%B9%E8%AF%9D%E6%9C%AF](https://gitee.com/zc10010/java_interview_guide/tree/master/知识点话术)



## 自我介绍

面试官您好，我是南京xx自动化学院一名学生，研二，24周岁。我的研究方向是多智能体深度强化学习。我在去年9月的时候开始自学Java，然后给自己制定了学习计划，除了科研之外，我每天会花大量的时间在学习Java上面。目前研究学习到的技术有JavaSE，JVM，JUC，MySQL，Redis，。我也深知我不是专业科班，所以在有限的时间内，我也在学习操作系统、计算机网络的知识。我也了解了一些大数据的技术，比如Hadoop、flink、hive。



我觉得我挺喜欢互联网这一行业的，它已经和我们的生活紧密联系在一起了。



为什么转Java，而不是其他语言

```
Java是强类型语言，静态类型语言。另外就是它的语法规范标准，如果学好了Java，转其他语言不难。
```

学了这么久自动化，转开发，不可惜吗？

```
我觉得自动化和计算机的知识虽然有差异，但是他们的很多思想是相似的。香农的信息论和维纳的控制论，奠定了计算机的发展。比如我的研究方向是多智能体强化学习，本质上就是一个分布式的系统，希望每个智能体能够像一个整体一样协调工作。开发也有分布式微服务，有很多服务器组成的集群。另外就是自动化针对一个系统，要研究他的鲁棒性，稳定性。开发一个程序应用，肯定也是希望他足够稳定，高可用（鲁棒性强）的。
```









## 反问环节



## 项目

https://gitee.com/XiYun0/mall

![image-20210330215553931](images/image-20210330215553931.png)

面试官你好

我先介绍一下，我在校期间做了一个模仿京东商城的项目，我个人认为当前微服务是大势所趋嘛，所以这个项目主要用的技术是SpringCloud，SpringCloudAlibaba组件。

```r
整个微服务架构的流程
1. 首先从手机、电脑等客户端发送请求到nginx集群
2. nginx将所有的请求转交给api网关，SpringCloud Gateway组件
3. 网关根据请求动态路由到指定服务（检索、商品、订单等）
	1. 如果某项服务过多，网关还会负载均衡Ribbon来调用该服务
	2. 如果某项服务出现问题，网关还会对服务做统一的`熔断、降级`SpringCloud Alibaba Sentinel组件
		1. 令牌限流，比如此时有100万个请求进来，如果没有限流，有可能把整个后台服务压垮，我们可以只放行1万个过去，让业务集群轻松处理完这些请求。
	3. 认证授权，看请求是否合法，合法了才放行
4. 请求最终来到了服务，使用了Springboot来编写的微服务。
5. 服务之间有可能会互相调用（订单调用商品，商品调用库存），使用的是SpringCloud Feign组件
6. 有些请求可能要登陆之后才能处理，所以需要一个OAuth2.0的认证中心，除了一般登陆，还有基于OAuth2.0的社交登陆（微博，微信）
7. 整个应用的安全权限控制使用SpringSecurity
8. 数据存储
    1. 缓存使用的Redis集群（哨兵集群+分片集群）
    2. 持久化存储数据使用的MySQL集群，读写分离、分库分表。
    3. 服务和服务之间使用`消息队列Rabbit集群`实现异步解耦、完成分布式事务的最终一致性。
    4. 有些服务有`全文检索`，比如检索商品信息，使用ElasticSearch
    5. 有些服务在运行期间要存储图片、视频等，使用阿里云的`对象存储服务`OSS
9. 为了快速定位项目中出现的问题，使用ELK进行相关的日志处理，使用LogStash收集业务的各种日志，把日志存储到ElasticSearch中，再使用Kibana可视化界面检索词相关的日志信息，帮我们快速定位，呈现问题所在。
10.在分布式系统中，每一个服务都可能部署在不同的机器，而且服务和服务之间要互相调用，就得知道彼此都在哪里，因此将所有的服务都注册到`注册中心`SpringCloud Alibaba nacos，然后别的服务可以到注册中心中去发现其他服务所在的位置。
11.同时，每一个服务的配置众多（比如商品服务可能有10台机器），因此要集中管理配置，实现改一处配置这些服务都能够自动修改掉。使用SpringCloud Alibaba nacos作为`配置中心`。
12.服务之间的调用可能会出现问题，比如订单服务调用商品服务，商品服务调用库存服务，某一个链路出现了问题，需要追踪调用链看哪里出现了问题，使用SpringCloud Sleuth（服务追踪） + Zinkin（可视化追踪）完成`链路追踪`，把每个服务的信息交给Prometheus进行聚合分析，再由Grafana进行可视化展示。通过Prometheus提供的Altermanager实时得到一些服务的告警信息，把这些告警信息以邮件或短信的方式通知开发或运维人员
```

项目主要分为几大模块，像通用模块、认证模块、商品模块、库存模块、优惠券模块、订单模块、秒杀模块。目前我已经完成了4个模块，大致的功能就是支撑商品系统的查询。

在做这个项目期间，我学到了很多知识。比如前端的vue、Element UI，缓存技术Redis，全文索引技术ElasticSearch。因为考虑成本和性能，我就在虚拟机上搭建了Docker环境，将MySQL、Redis以及Nginx都放到了Docker上。



### 人人开源

使用了gitee上人人开源的代码生成器，逆向生成了与各数据库表对应的基本entity、service、mapper。

前端用了vue，后台管理系统用的renrenfast。



最后呢，我也做了一些总结，我自学Java的时间不长，还有很多技术没有接触到，但是我觉得我是那种喜欢钻研技术的人，相信可以跟各位前辈手下学习，成长得更快。

### Nginx、网关

我在项目中使用了Nginx，都知道Nginx有负载均衡、反向代理的能力嘛，我在Nginx的nginx.conf中配置了upstream组，将前端的请求代理到网关API，网关也是一个服务，使用的是Gateway（这个gateway的性能比zuul1的性能高1.6倍），让网关动态路由到指定的服务模块。并且我还将前端的静态资源都放到了Nginx里面，这种动静分离可以让整个系统更快。

```yml
- id: gulimall_host_route
  uri: lb://gulimall-product	# 动态路由到到这个模块
  predicate: 
  	- Host=gulimall.com

```





### 分库分表

因为订单的数据量比较大，我这边就考虑用Mycat，分库分表，这样数据库的压力有所减轻。在数据库中间件之前，我还用到了Redis+token 令牌机制登陆，这个方法能够解决传统session登陆的问题，像集群服务器当中这个session共字的问题，这个session的效率不高，还耗费资源。

### 压力测试

我还使用了Apache的高并发压力测试工具，叫Jmeter。这个工具可以模拟多线程情况下多个用户抢购的情况。我测试了发现分布式锁的效率比较低，所以我又引入了RabbitMQ来解决效率低下的问题，实现流量消峰。就是用户在发送一个抢购的请求时，用户会得到一个排队成功的返回信息。









### 分布式缓存

我在Product模块写了商品分类查询业务嘛，查询商品分类的数据访问量肯定很大，而且这些数据往往不怎么修改（读多写少），每次都要走数据库会很麻烦，会影响系统的性能，所以我就考虑引入缓存，这样数据库只要承担持久化工作，在第一次从数据库查到数据后，就把数据放到缓存里边。

缓存分为本地缓存、分布式缓存，比如HashMap就可以充当本地缓存，因为它是在内存中的，然后我这个项目又是微服务项目，不是单纯的单机系统，本地缓存在微服务系统中会出现数据不一致的问题，我在前面用了负载均衡，一个请求过来发现1台服务器上，在数据库查询到了数据，放到本地缓存，然后负载均衡到另一台机器是机器上，此时又要走数据库；更严重的是，如果对数据库的数据进行了修改，那么其他服务器的缓存会出现数据完全不一致的现象！……所以考虑使用`分布式缓存`，在缓存中间件的技术选型上，我使用了Redis，Redis的好处很多，比如可以构成理论上的无限量集群，没有容量限制！一台机器上放1-10000的数据，下一台放10001-20000的数据……

```java
在pom中引入 Spring-boot-started-redis
在需要加入缓存的service中，加入
	@Autoried
	private StringRedisTemplate redistemplate;
```







```java
data = cache.load(id);	// 查看缓存中是否有数据
if(data == null){		// 如果没有（未命中），那么从数据库中加载
    data = db.load(id);
    cache.put(id, data);	// 保存到缓存中
}
return data;
```

> 最简单的缓存就是HashMap了

```java
Map<String, Object> cache = new HashMap<>();
Object object = cache.get("xxx");
if (object == null){
    ......
    cache.put("", );
}
return 
```



在缓存上，我也总结了一些，就是即时性要求不高和读多写少的数据都是可以考虑使用缓存技术的。

我也考虑了`缓存的问题`：

1. 读模式：缓存穿透，缓存击穿，缓存雪崩。`缓存穿透`就是查询null数据，解决的办法就是缓存空数据。`缓存击穿`就是大量并发进来查询一个正好过期的数据，解决方式就是加锁，我将所有服务都加上锁，如果要查询数据库了，只让一个人来查，下次再进来一个人，他得到锁了才能进行操作。`缓存雪崩`就是大量的key同时过期，解决办法是加随机时间。
2. 写模式：缓存和数据库不一致的问题，解决方法是读写加锁。或者就是引入canal，可以感知到MySQL的更新去更新数据库。或者就是读多写多，就直接查询数据库就行了。

#### 缓存一致性

双写模式：改完数据库，也改一下缓存。

失效模式：改完数据库，删掉缓存

最佳的解决方案是用阿里开源的canal。我这个系统的缓存数据一致性方案

1、缓存的所有数据都有过期时间，数据过期下一次查询触发主动更新。
2、读写数据的时候，加上分布式的读写锁。在更新分类数据的时候，删除缓存中的旧数据。

### 分布式锁

以前是单机应用程序嘛，所以用本地锁 synchronized、Lock锁就可以了。但是现在有多个分布式服务，也就需要分布式锁了。Redis在Java中的分布式锁实现就是Redisson。我就使用Redisson作为分布式锁，具体做法就是从maven仓库中找到Redisson的依赖，然后添加到pom文件中，然后就是在config包下面加入配置。

```
导入依赖 -> 添加config{ new Config(), Redisson.create()} -> 注入配置
```



```java
@Bean
public RedissonClient redisson(){
	// 创建配置
    CConfig config = new Config();
    config.useSingleServer().setAddress("redis://192.168.75.104:6379");
    // 根据配置创建出实例
    RedissonClient redissonClient = Redisson.create(config);
    return redissonClient;
}
```

Redisson和juc的本地锁使用方法差不多。因为Rlock继承了Lock接口。

```java
RLock lock = redisson.getLock("my-lock");	// 这个Rlock 继承了 Lock接口 
```

Redisson不会出现死锁





### 异步、线程池

因为有些业务比较复杂，所以我还用到了线程池。

比如商品详情页，有sku商品信息，还有sku图片等待。所以这边我考虑使用CompletableFuture，有runAsync和suplyAsync，来完成任务。



### Cookies、Session

比如登陆京东网站的时候，京东的服务器那头会发一个user-key给浏览器，这个user-key就在cookie，value就是UUID的格式。

现在基本上所有网站在登陆完成后都会记录登陆信息嘛，所以就要用到session。session用的redis存储。



### 购物车Cart

大部分商城都是有购物车的，好像就拼多多没有。购物车显然是读写都是高并发的，使用mysql会有很大压力，应该使用nosql数据库，mongodb，redis。

redis是基于内存的，要是宕机了话，临时购物车的数据就消失了，前端是可以存储的而且后台还没有压力，但是为了服务大数据推荐系统，有价值的数据应该放在后端，所以就用到了持久化技术，rdb和aof。

购物车肯定不止一条数据，一个购物项就应该是一个对象，若干个购物项组成了一个数组`[{   },{   },{   }]`。

redis那边用的是hash存储的，可以更加购物项的key来找到值的位置。

```
Map<String k1,Map<String k2,Carttemlnfo>>
k1:标识每一个用户的购物车
k2:购物项的商品id
```



>题外话，列式存储按字段，类似于对象的属性存储。行式存储Redis，按行，每一行都有value，value里面有一堆的属性。

> 题外话，列式存储和行式存储。列式存储MySQL，按字段，类似于按照对象的属性，



#### ThreadLocal作为拦截器

拦截会查看是临时用户还是永久用户

### 秒杀系统

秒杀服务是一个高并发的服务，



## 基础

#### 单例模式

私有静态属性，私有构造方法，静态方法getInstance()，返回类型就是本类;if 私有静态成员变量为nul，那么new 构造方法。

#### 重载重写的区别

**重载**： 发生在同一个类中，方法名必须相同，参数类型不同，个数不同，顺序不同，与方法的修饰符和返回值无关

**重写**： 发生在父子类中，方法名.参数列表必须相同，返回值范围小于等于父类，抛出的异常范围小于等于父类

#### 值传递和引用传递

值传递呢就是传递的过程中，传递的是值，对值操作之后，不会影响原有变量的值

引用传递就是传递的过程中，传递的是引用，操作引用之后，会影响原有变量的值

- 在传递的过程中，如果传递的是基本数据类型以及String，那么都是值传递，不会改变原有变量
- 在传递的过程中，如果传递的是对象，如果修改了属性的值，那么会直接改动原有对象，会影响外面的值，如果没有修改对应的属性值，那么原有对象不受任何影响。

#### int、Integer自动拆箱、装箱介绍

装箱就是 自动将基本数据类型转换为包装类型；

拆箱就是 自动将包装类型转换为基本数据类型；

在定义变量的时候，比如`Integer num = 1;`就会自动装箱成Integer对象操作，`int num2 = num;`就会进行自动拆箱操作

在比较的时候，也会会发生拆箱和装箱操作

- 无论如何，Integer与new Integer不会相等。不会经历拆箱过程
- 两个都是非new出来的Integer，如果数在-128到127之间，则是true,否则为false
- 两个都是new出来的,都为false
- int和Integer或者new Integer比较，都为true，因为会把Integer自动拆箱为int再去比

#### String 和 StringBuffer,StringBuilder 的区别是什么

从可变性来说呢，String底层呢其实就是个char数组，当然后面就变成byte数组了，使用final修饰了，所以是不可变的，StringBuilder 与 StringBuffer是可变的字符串

从安全上来说，String 中的对象是不可变的，也就可以理解为常量，线程安全。StringBuffer 对方法加了同步锁或者对调用的方法加了同步锁，所以是线程安全的。StringBuilder 并没有对方法进行加同步锁，所以是不线程安全的。

从性能上来说，每次对 String 类型进行改变的时候，都会生成一个新的 String 对象，然后将指针指向新的String 对象。StringBuffer 每次都会对 StringBuffer 对象本身进行操作，而不是生成新的对象并改变对象引用。StirngBuilder的效率会高一些，而StringBuffer的底层加了同步的关键字，性能会有所下降

所以呢，一般我们操作少量的字符串的时候用String ，在单线程环境下操作大量数据时使用StringBuilder，在多线程操作大量数据使用StringBuffer

#### final、finally、finalize的区别

final是一个安全修饰符,就是用final修饰的类不能被继承,用final声明的方法不能被重写,使用final声明的变量就相当于常量,不能被修改。

至于为什么不可变，因为有一个putfield指令 加入写屏障。

finally是在异常里经常用到的，就是try和cach里的代码执行完以后，必须要执行的方法，我们经常在finally里写一些关闭资源的方法，关闭IO流什么的，就算是try和catch里有return代码，也会执行finally里的内容的，除非在try catch里遇到System.exit代码，整个主线程就停掉了，才不会执行finally里的代码

finalize是Object类的一个方法，在垃圾收集器执行的时候会调用被回收对象的此方法，可以被垃圾回收

#### 接口和抽象类的区别

- 接口的方法默认是 public，所有方法在接口中不能有实现，不过在Java 8 开始接口方法可以有默认实现，抽象类可以有非抽象的方法
- 接口中的实例变量默认是 final 类型的，而抽象类中则不一定
- 一个类可以实现多个接口，但最多只能实现一个抽象类
- 一个类实现接口的话要实现接口的所有方法，而抽象类不一定
- 接口不能用 new 实例化，但可以声明，但是必须引用一个实现该接口的对象，从设计层面来 说，抽象是对类的抽象，是一种模板设计，接口是行为的抽象，是一种行为的规范。

#### 深拷贝和浅拷贝

先说一下浅拷贝吧，就是如果对一个对象进行拷贝的时候，对他的基本数据类型进行了拷贝，但是对引用数据类型进行了引用传递，没有创建一个新的对象，那么可以说这是浅拷贝。

#### 序列化

#### Java的基本数据类型

基本数据类型有8中，分别是`byte、short、int、long float、double、char、boolean`，对应基本类型，都会有一个封装类

#### jdk1.8的新特性

这块的话，我先说一些我们项目中经常会用到的吧

首先呢就是lamda表达式这块，遍历集合以及定义匿名函数，简直是非常方便

还有就是switch中的变量可以是string类型了，之前只能是基本数据类型

还有就是stream流式编程，这个的话可以让我们用strem的方式可以非常方便的对集合里的数据操作

还有就是新的时间类，LocalDate、LocalTime、LocalDateTime这几个类，让我们操作日期的时候非常方便，既可以自定义日期，还可以对年月日时分秒随时进行加减，以及快速格式化和强转等

还有就是其他一些我从别人的博客里看到的，我做的这些项目中没遇到过，就像Java 8允许我们给接口添加一个非抽象的方法实现，只需要使用 default关键字就行了，给我的感觉就是，我们在接口里定义一些初始化方法很方便了，不用在每个实现类里都实现一遍了，也是非常方便的

#### JVM类加载的过程

我理解的过程呢就是：将类的数据 从 Class 文件加载到内存 ，并且对数据进行校验、转换解析和初始化，最终形成可被虚拟机直接使用的 Java 使用类型

java 类加载过程呢包括：**加载**-->**验证**-->**准备**-->**解析**-->**初始化**，之后类就可以被使用了。绝大部分情况下是按这样的顺序来完成类的加载全过程的。但是是有例外的地方，解析也是可以在初始化之后进行的，这是为了支持 java 的运行时绑定，并且在一个阶段进行过程中也可能会激活后一个阶段，而不是等待一个阶段结束再进行后一个阶段。

再说具体一点就是

- 首先加载Student.class文件进内存
- 在栈内存为s开辟空间
- 在堆内存为学生对象开辟空间
- 对学生对象的成员变量进行默认初始化
- 对学生对象的成员变量进行显示初始化
- 通过构造方法对学生对象的成员变量赋值
- 学生对象初始化完毕，把对象地址赋值给s变量

#### 介绍下反射

简单说，在 Java 中的反射机制是指在运行状态中，对于任意一个类都能够知道这个类所有的属性和方法，并且对于任意一个对象，都能够调用它的任意一个方法；这种动态获取信息以及动态调用对象方法的功能就是 Java 语言的反射机制。

在java 中，只要给定类的名字，那么就可以通过反射机制来获得类的所有信息。反射的作用其实就是：在运行时能够判断任意一个对象所属的类, 还有就是在运行时构造任意一个类的对象,我们常用的Spring框架也是利用Java反射这一块架构的，还有就是在运行时判断任意一个类所具有的成员变量和方法,还能在在运行时调用任一对象的方法，还有在运行时创建新类对象

一般都是使用`Class clazz=Class.forName("类的全路径")`这个方法，获取到class，获取到了之后，可以获取到类中所有的method方法，和所有的属性，调用Method的invoke方法就可以执行该方法，但是如果是私有方法的话，必须通过getDeclaredMethod获取，还需要调用方法的setAccessible设置为true才可以执行。

#### 说一下常见的异常

最常见的莫过于空指针NullPointException了，一般都是空对象调用他的方法了

还有就是FileNotFound异常了，在文件操作的时候，一不小心路径写错了，或者是windows切换linux的时候，因为路径格式不一致，经常会有这个错误

还有就是ClassCastException，类转换异常，这块从json中的数据转换成类的时候经常会出现

接着就是SQLException，非常熟悉的错误信息就是`Unknown column xxx`，这种错误的话，就是列名错了，还有就是 `You have an error in your SQL syntax,check xxxx near xxx`，这个错误就是sql语法错误，异常信息会指出来错误的具体地方，还有就是`Result consisted of more than one row`，这个的话发生在selectOne方法的时候，想要获取一个结果集，但是返回了好多个



## JVM



## 容器

#### HashMap底层原理

我先给您说一下我理解的HashMap吧

在jdk1.8之前，底层是通过数组+链表实现的，当我们创建hashmap时会先创建一个数组，当我们用put方法存数据时，先根据key的hashcode值计算出hash值，然后用这个哈希值确定在数组中的位置，再把value值放进去，如果这个位置本来没放东西，就会直接放进去，如果之前就有，就会生成一个链表，把新放入的值放在头部，当用get方法取值时，会先根据key的hashcode值计算出hash值，确定位置，再根据equals方法从该位置上的链表中取出该value值，当容量超过当前容量的0.75倍之后，就会自动扩容为原来容量的2倍。这个0.75就是负载因子。

但是在jdk1.8之后，HashMap 进行了一些修改，最大的不同就是利用了红黑树，所以其由 数组+链表+ 红黑树组成。因为在1.7的时候，这个链表的长度不固定，所以如果key的hashcode重复之后，那么对应的链表的数据的长度就无法控制了，get数据的时间复杂度就取决于链表的长度了，为了提高这一部分的性能，加入了红黑树，如果链表的长度超过8位之后，会将链表转换为红黑树，极大的降低了时间复杂度

HashMap 线程不安全，即任一时刻可以有多个线程同时 写 HashMap，可能会导致数据的不一致。如果需要满足线程安全，可以用 Collections 的 synchronizedMap 方法使 HashMap 具有线程安全的能力，或者使用 ConcurrentHashMap。

#### 介绍下ConcurrentHashMap

> 也可以被问成：线程安全的HashMap类有哪些，ConcurrentHashMap如何保证线程安全

ConcurrentHashMap是线程安全的HashMap，内部采用了的"分段锁"策略，ConcurrentHashMap的主干是个Segment数组。Segment 通过继承ReentrantLock 来进行加锁，所以每次需要加锁的操作锁住的是一个 segment，这样只要保证每个 Segment 是线程安全的，也就实现了全局的线程安全。一个Segment就是一个子哈希表，Segment里维护了一个HashEntry数组，默认有16 个 Segment，所以理论上，最多可以同时支持 16 个线程并发写，只要它们的操作分别分布在不同的 Segment 上。



## JUC

#### 创建线程的方式

首先呢，Thread 类本质上是实现了 Runnable 接口，代表一个线程的实例。所以我们可以编写一个类，`继承Thread类`，或者直接`实现Runnable接口`，然后再重写下run方法就行了。启动线程的方式就是调用类里边的 start方法。start()方法是一个 native 方法，它的作用就是启动线程，线程会去执行 run()方法中的代码。

还有就是`实现 Callable 接口`，这个接口相当于是Runnable接口的增强版，他的执行代码的方法不是run方法了，是call方法，这个call方法可以有返回值，我们可以创建一个 FutureTask 类的实例对象，通过他的get()方法得到执行结果，不过这里定的执行结果需要跟FutureTask的泛型一致才行，并且call方法还可以抛出异常，通过这些，我们就能很明确的知道线程内部的执行状态。

还有就是通过`线程池`来实现，线程池就是事先将多个线程对象放到一个容器中，当使用的时候就不用 new 线程而是直接去池中拿线程即可，节省了开辟子线程的时间，提高的代码执行效率。 一般创建线程池的话，都是使用个的Executors 类中提供的创建线程池的静态方法。他可以创建4种线程池，有

FixedThreadPool，创建固定大小的线程池，比如线程池容量是10，最多可以同时执行10个线程。

CachedThreadPool，创建一个可缓存的线程池，此线程池不会对线程池大小做限制，线程池大小完全依赖于JVM能够创建的最大线程大小，当然线程池里的线程是可以复用的，但是如果在高并发的情况下，这个线程池在会导致运行时内存溢出问题

ScheduledThreadPool，创建一个定时执行的线程池，里边提供了两个方法，FixRate和fixDelay，fixRate就是以固定时间周期执行任务，不管上一个线程是否执行完，fixDelay的话就是以固定的延迟执行任务，就是在上一个任务执行完成之后，延迟一定时间执行。

SingleThreadExecutor，创建一个单线程的线程池，这个线程池同时只能执行一个线程，可以保证线程按顺序执行，保证数据安全。



execute和submit的区别在于，前者没有返回值，只有执行任务。

```
区别：
1、2不能得到返回值。3可以获取返回值
1、2、3都不能控制资源
4可以控制资源，性能稳定。如果有100万个请求进来，每来一个请求就要开启一个线程，很快就会资源耗尽。任何一个高并发系统都是求稳为主！
```



#### 线程的状态

线程有6种状态，就是从`new`到`Runnable`到`阻塞`到`等待`到`超时等待`到`终止`。当我们new一个线程的时候，就是new状态了。这个时候要是调用了start方法，那么线程将会进入可运行状态，当然这个可运行状态也是有两个小状态的，分别是就绪和运行。就绪就是在等待时间片。

#### 线程都有哪些方法

线程里的方法有很多，我给您说说我们常用的方法吧

wait方法呢就是线程等待，调用这个方法之后，线程进入 waiting 状态，只有等待通知notify或者notifyAll才会继续执行，这个时候 会释放对象的锁。因此呢，wait 方法一般用在同步方法或同步代码块中。

sleep线程睡眠，让当前线程休眠，此时线程处于阻塞的状态，当前线程进入timed-waiting状态

yield线程让步，我看源代码的意思是释放CPU资源，让其他线程抢夺CPU资源，实际用的时候，大概就是让当前线程先暂停，让其他线程先运行

join线程插队，我理解的呢就是让当前线程先运行，其他线程先等待，等运行完在执行其他线程

interrupt线程中断，这个就是中断当前线程的意思

notify唤醒线程，notifyAll唤醒所有线程

#### sleep和wait的区别

我之前写代码的时候也一直会用到这两个方法，我总结的区别大致分了三个方面

首先就是sleep不会释放锁，而wait会释放锁。

接着呢就是sleep不会解除cpu占用，wait会释放cpu资源

然后还有就是sleep会导致线程阻塞，时间到了之后，线程继续向下执行，但是wait必须配合notify或者notifyAll来唤醒

#### JMM了解吗

JMM是Java内存模型的意思，他是一种理论概念。分为可见性，原子性，有序性。

我先说一下可见性吧。就是加入现在有一个主物理内存，里面有共享变量。现在多个线程进来，每个线程有自己的工作内存，将共享变量拷贝到工作内存，如果有一个线程修改了值，并写会主内存，此时其他线程是不知道的。这就是不保证可见性

```
jmm可见性，多个线程就是班上的学生，每个线程都有自己的工作内存，这个工作内存就和口袋一样，讲台上就是主物理内存，讲台上的纸条就是共享变量，每个线程现在都会将纸条复制一份到自己的口袋，如果修改写会主内存，其他线程不知道发生了啥，但是如果有班主任，打开纸条
```

#### ThreadLocal

在主物理内存里面创建一个ThreadLocal的变量，如果多个线程进来访问，此时，会复制一个副本变量，到自己的工作内存中进行操作。

#### 介绍下你理解的线程中的锁

我理解的锁的话，就是在多个线程同时访问一个数据的时候，为了保证数据的安全性，我们需要对数据操作的代码进行加锁处理，一般来说这个锁需要是对所有线程是一致的，一般可以用静态变量来作为锁，这个锁用synchronized关键字来包裹着，当这段代码块执行完之后，释放锁，然后其他线程获取到这个锁之后，才能执行这段代码，通过锁的机制很好的保护了多线程下的数据安全

但是在用锁的时候，如果使用不当的话会导致死锁的问题，就是A线程等待B释放锁，B线程同时在等待A释放锁，这样的话就会导致两个线程相互等待，造成死锁，所以在使用的时候尽量避免多线程之间相互依赖锁的情况发生

还有对锁的分类的话，分为乐观锁和悲观锁

乐观锁的话就是比较乐观，每次去拿数据的时候，认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制或者CAS 算法实现。乐观锁在读操作比较多的场景比较适用，这样可以提高吞吐量，就像数据库提供的write_condition机制，其实都是乐观锁

悲观锁的话就是每次去拿数据的时候，也认为别人会修改数据，这个时候就会加上锁，这就导致其他线程想拿数据的话，就会阻塞，直到这个线程修改完成才会释放锁，让其他线程获取数据。在数据库里的行级锁、表级锁都是在操作之前就先锁住数据再操作数据 ，都属于悲观锁。Java中的 synchronized 和 ReentrantLock 等独占锁就是悲观锁思想的实现

#### 线程池的原理

我之前看过线程池相关的源码，线程池主要由4个部分组成，

- 线程池管理器：用于创建并管理线程池
- 工作线程：线程池中的线程
- 任务接口：每个任务必须实现的接口，用于工作线程调度其运行
- 任务队列：用于存放待处理的任务，提供一种缓冲机制

线程池做的工作主要是控制运行的线程的数量，处理过程中将任务放入队列，然后在线 程创建后启动这些任务，如果线程数量超过了最大数量，超出数量的线程排队等候，等其它线程执行完毕，再从队列中取出任务来执行。他的主要特点为：线程复用；控制最大并发数；管理线程。

#### 线程池的核心参数都有哪些

- **corePoolSize**（核心线程数）

  （1）核心线程会一直存在，即使没有任务执行；

  （2）当线程数小于核心线程数的时候，即使有空闲线程，也会一直创建线程直到达到核心线程数；

  （3）设置 allowCoreThreadTimeout=true（默认 false）时，核心线程会超时关闭。

- **queueCapacity**（任务队列容量）

  （1）也叫阻塞队列，当核心线程都在运行，此时再有任务进来，会进入任务队列，排队等待线程执行。

- **maxPoolSize**（最大线程数）

  （1）线程池里允许存在的最大线程数量；

- **keepAliveTime**（线程空闲时间）

  （1）当线程空闲时间达到 keepAliveTime 时，线程会退出，直到线程数等于核心线程数



### 锁

#### 介绍一下乐观锁和悲观锁

乐观锁的话就是比较乐观，每次去拿数据的时候，认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制或者CAS 算法实现。乐观锁在读操作比较多的场景比较适用，这样可以提高吞吐量，就像数据库提供的write_condition机制，其实都是乐观锁

悲观锁的话就是每次去拿数据的时候，也认为别人会修改数据，这个时候就会加上锁，这就导致其他线程想拿数据的话，就会阻塞，直到这个线程修改完成才会释放锁，让其他线程获取数据。在数据库里的行级锁、表级锁都是在操作之前就先锁住数据再操作数据 ，都属于悲观锁。Java中的 synchronized 和 ReentrantLock 等独占锁就是悲观锁思想的实现

Java中各种锁其实都是悲观锁的实现，在操作数据的时候，数据都会被当前线程锁住。

#### 2、介绍一下公平锁和非公平锁

公平锁：指线程在等待获取同一个锁的时候，是严格按照申请锁的时间顺序来进行的，这就意味着在程序正常运行的时候，不会有线程执行不到的情况，但是也需要额外的机制来维护这种顺序，所以效率相对于非公平锁会差点

非公平锁：概念跟“公平锁”恰恰相反，随机线程获取锁，效率相对高，可能会导致某些线程一直获取不到CPU资源而执行不到

创建一个ReentrantLock默认就是非公平锁，当然也可以传入参数让他变成公平锁

```
new ReentrantLock(); //默认非公平锁 
new ReentrantLock(true); //公平锁
```

#### 3、重入锁（递归锁）和不可重入锁（自旋锁）

```
//demo不用记忆，理解代码
public class Demo {
  private Lock lockA;//这是个锁
 
  public Demo(Lock Lock) {
    this.lockA = lock;
  }
 
  public void methodA() {//业务逻辑A
    lockA.lock();//获取锁，加锁
    methodB();//执行业务逻辑B
    lockA.unlock();//解锁
  }
 
  public void methodB() {//业务逻辑B
    lockA.lock();//同样获取锁，加锁操作
    //dosm
    lockA.unlock();//解锁
  }
  
}
```

重入锁：当我们运行methodA()的时候，线程获取了lockA，然后调用methodB()的时候发现也需要lockA，由于这是一个可重入锁，所以当前线程也是可以直接进入的。在java中，synchronized跟ReetrantLock都是可重入锁。

不可重入锁：methodA进入methodB的时候不能直接获取锁，必须先调用unLock释放锁。才能执行下去

#### 4、共享锁和独占锁

java 并发包提供的加锁模式分为独占锁和共享锁。

**独占锁**

独占锁模式下，每次只能有一个线程能持有锁，ReentrantLock 就是以独占方式实现的互斥锁。独占锁是一种悲观保守的加锁策略，它避免了线程之间读取数据发生冲突，如果某个只读线程获取锁，则其他读线程都只能等待

**共享锁**

共享锁则允许多个线程同时获取锁，并发访问 共享资源，比如说：ReadWriteLock。共享锁则是一种乐观锁，它放宽了加锁策略，允许多个执行读操作的线程同时访问共享资源。

#### 5、synchronized和threadlocal的区别

synchronized关键字主要解决多线程共享数据的同步问题。

ThreadLocal使用场合主要解决多线程中数据因并发产生不一致问题。

ThreadLocal和Synchonized都用于解决多线程并发访问，但是ThreadLocal与synchronized有本质的区别: synchronized是利用锁的机制，使变量或代码块在某一时该只能被一个线程访问。而ThreadLocal是为每一个线程都提供了变量的副本，使得每个线程在某一时间访问到的并不是同一个对象，这样就隔离了多个线程对数据的数据共享。在使用完成后需要注意的是，需要把threadlocal里的数据移除。

而Synchronized却正好相反，它用于在多个线程间通信时能够获得数据共享。



## Spring

#### 介绍一下spring

关于Spring的话，我们平时做项目一直都在用，不管是使用ssh还是使用ssm，都可以整合。Spring里面主要的就三点，也就是核心思想，IOC控制反转，DI依赖注入，AOP切面编程

我先来说说IOC吧，IOC就是spring里的控制反转，把类的控制权呢交给spring来管理，我们在使用的时候，在spring的配置文件中，配置好bean标签，以及类的全路径，如果有参数，然后在配置上相应的参数。这样的话，spring就会给我们通过反射的机制实例化这个类，同时放到spring容器当中去。

```java
Class clazz = Class.forname("");
clazz.newInstance();
```

我们在使用的时候，需要结合DI依赖注入使用，把我们想使用的类注入到需要的地方就可以，依赖注入的方式有构造器注入、getset注入还有注解注入。我们现在都使用`@autowired`或者`@Resource`注解的方式注入。

然后就是AOP切面编程，他可以在不改变源代码的情况下对代码功能的一个增强。我们在配置文件中配置好切点，然后去实现切面的逻辑就可以实现代码增强，这个代码增强，包括在切点的执行前，执行中，执行后都可以进行增强逻辑处理，不用改变源代码，这块我们项目中一般用于权限认证、日志、事务处理这几个地方。

#### AOP的实现原理

这块呢，我看过spring的源码，底层就是动态代理来实现的，所谓的动态代理就是说 AOP 框架不会去修改字节码，而是每次运行时在内存中临时为方法生成一个 AOP 对象，这个 AOP 对象包含了 ，目标对象的全部方法，并且在特定的切点做了增强处理，并回调原对象的方法。

Spring AOP 中的动态代理主要有两种方式，JDK 动态代理和 CGLIB 动态代理：

- JDK 动态代理只提供接口的代理，不支持类的代理。核心InvocationHandler 接口和 Proxy 类，InvocationHandler 通过 invoke()方法反射来调用目标类中的代码，动态地将横切逻辑和业务编织在一起；接着，Proxy 利用InvocationHandler 动态创建一个符合接口的的实例，生成目标类的代理对象。
- 如果代理类没有实现 InvocationHandler 接口，那么 Spring AOP 会选择使用 CGLIB 来动态代理目标类。CGLIB（Code Generation Library），是一个代码生成的类库，可以在运行时动态的生成指定类的一个子类对象，并覆盖其中特定方法并添加增强代码，从而实现 AOP。CGLIB 是通过继承的方式做的动态代理，因此如果某个类被标记为 final，那么它是无法使用 CGLIB 做动态代理的。不过在我们的业务场景中没有代理过final的类，基本上都代理的controller层实现权限以及日志，还有就是service层实现事务统一管理

#### 详细介绍下IOC容器

Spring 提供了两种 IoC 容器，分别为 BeanFactory 和 ApplicationContext

BeanFactory 是基础类型的 IoC 容器，提供了完整的 IoC 服务支持。简单来说，BeanFactory 就是一个管理 Bean 的工厂，它主要负责初始化各种 Bean，并调用它们的生命周期方法。

ApplicationContext 是 BeanFactory 的子接口，也被称为应用上下文。它不仅提供了 BeanFactory 的所有功能，还添加了对 i18n（国际化）、资源访问、事件传播等方面的良好支持。

他俩的主要区别在于，如果 Bean 的某一个属性没有注入，则使用 BeanFacotry 加载后，在第一次调用 getBean() 方法时会抛出异常，但是呢ApplicationContext 会在初始化时自检，这样有利于检查所依赖的属性是否注入。

因此，在实际开发中，通常都选择使用 ApplicationContext

#### `@Autowired` 和 `@Resource`的区别

```
@Autowired` 默认是按照类型注入的，如果这个类型没找到，会根据名称去注入，如果在用的时候需要指定名称，可以加注解`@Qualifier("指定名称的类")
@Resource`注解也可以从容器中注入bean，默认是按照名称注入的，如果这个名称的没找到，就会按照类型去找，也可以在注解里直接指定名称`@Resource(name="类的名称")
```

#### springbean的生命周期

生命周期这块无非就是从创建到销毁的过程

spring容器可以管理 singleton 作用域 Bean 的生命周期，在此作用域下，Spring 能够精确地知道该 Bean 何时被创建，何时初始化完成，以及何时被销毁。

而对于 prototype 作用域的 Bean，Spring 只负责创建，当容器创建了 Bean 的实例后，Bean 的实例就交给客户端代码管理，Spring 容器将不再跟踪其生命周期。每次客户端请求 prototype 作用域的 Bean 时，Spring 容器都会创建一个新的实例，并且不会管那些被配置成 prototype 作用域的 Bean 的生命周期。

整体来说就4个步骤：实例化bean，属性赋值，初始化bean，销毁bean

- 首先就是实例化bean，容器通过获取BeanDefinition对象中的信息进行实例化
- 然后呢就是属性赋值，利用依赖注入完成 Bean 中所有属性值的配置注入
- 接着就是初始化bean，如果在配置文件中通过 init-method 属性指定了初始化方法，则调用该初始化方法。
- 最后就是销毁bean，和init-method一样，通过给destroy-method指定函数，就可以在bean销毁前执行指定的逻辑

#### springbean的作用域

Spring 容器中的 bean 可以分为 5 个范围：

（1）singleton：单例模式，使用 singleton 定义的 Bean 在 Spring 容器中只有一个实例，这也是 Bean 默认的作用域。 controller、service、dao层基本都是singleton的

（2）prototype：原型模式，每次通过 Spring 容器获取 prototype 定义的 Bean 时，容器都将创建一个新的 Bean 实例。

（3）request：在一次 HTTP 请求中，容器会返回该 Bean 的同一个实例。而对不同的 HTTP 请求，会返回不同的实例，该作用域仅在当前 HTTP Request 内有效。

（4）session：在一次 HTTP Session 中，容器会返回该 Bean 的同一个实例。而对不同的 HTTP 请求，会返回不同的实例，该作用域仅在当前 HTTP Session 内有效。

（5）global-session：全局作用域，在一个全局的 HTTP Session 中，容器会返回该 Bean 的同一个实例。

#### 事务的传播特性

> 解读：事务的传播特性发生在事务方法与非事物方法之间相互调用的时候，在事务管理过程中，传播行为可以控制是否需要创建事务以及如何创建事务

| 属性名称                  | 值            | 描 述                                                        |
| ------------------------- | ------------- | ------------------------------------------------------------ |
| PROPAGATION_REQUIRED      | required      | 支持当前事务。如果 A 方法已经在事务中，则 B 事务将直接使用。否则将创建新事务，默认就是这个 |
| PROPAGATION_SUPPORTS      | supports      | 支持当前事务。如果 A 方法已经在事务中，则 B 事务将直接使用。否则将以非事务状态执行 |
| PROPAGATION_MANDATORY     | mandatory     | 支持当前事务。如果 A 方法没有事务，则抛出异常                |
| PROPAGATION_REQUIRES_NEW  | requires_new  | 将创建新的事务，如果 A 方法已经在事务中，则将 A 事务挂起     |
| PROPAGATION_NOT_SUPPORTED | not_supported | 不支持当前事务，总是以非事务状态执行。如果 A 方法已经在事务中，则将其挂起 |
| PROPAGATION_NEVER         | never         | 不支持当前事务，如果 A 方法在事务中，则抛出异常              |
| PROPAGATION.NESTED        | nested        | 嵌套事务，底层将使用 Savepoint 形成嵌套事务                  |

#### 事务的隔离级别

Spring 事务的本质其实就是数据库对事务的支持，没有数据库的事务支持，spring是无法提供事务功能的。真正的数据库层的事务提交和回滚是通过 binlog实现的。隔离级别有四种

- Read uncommitted (读未提交)：读未提交，允许另外一个事务可以看到这个事务未提交的数据，最低级别，任何情况都无法保证。会造成脏读，读到了别的事务还没提交的数据。
- Read committed (读已提交)：保证一个事务修改的数据提交后才能被另一事务读取，而且能看到该事务对已有记录的更新，可避免脏读的发生。但是这种隔离级别会造成不可重复读，就是一个事务A修改提交后，事务B读到了，但是过了会儿事务A又修改了，此时事务B读的又不一样，不可重复。
- Repeatable read (可重复读)：保证一个事务修改的数据提交后才能被另一事务读取，但是不能看到该事务对已有记录的更新，可避免脏读、不可重复读的发生。这个级别会有幻影读的问题。本质上就是加了个`行锁`。
- Serializable (串行化)：一个事务在执行的过程中完全看不到其他事务对数据库所做的更新，可避免脏读、不可重复读、幻读的发生。本质上就是加了个`表锁`。

#### spring中都用了哪些设计模式

（1）工厂模式：BeanFactory就是简单工厂模式的体现，用来创建对象的实例；这种设计模式可以解耦，工厂里面加上静态方法，然后用反射，然后还从配置文件里面拿到kv，这个k就是反射要的类全路径。

（2）单例模式：Bean默认为单例模式。

（3）代理模式：Spring的AOP功能用到了JDK的动态代理和CGLIB字节码生成技术；

（4）模板方法：用来解决代码重复的问题。比如. RestTemplate, JmsTemplate, JpaTemplate。

（5）观察者模式：定义对象键一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都会得到通知被制动更新，如Spring中listener的实现–ApplicationListener。

#### spring中如何处理bean在线程并发时线程安全问题

在一般情况下，只有无状态的 Bean 才可以在多线程环境下共享，在 Spring 中，绝大部分 Bean 都可以声明为 singleton 作用域，因为 Spring 对一些 Bean 中非线程安全状态采用 ThreadLocal 进行处理，解决线程安全问题。

ThreadLocal 和线程同步机制都是为了解决多线程中相同变量的访问冲突问题。同步机制采用了“时间换空间”的方式，仅提供一份变量，不同的线程在访问前需要获取锁，没获得锁的线程则需要排队。而 ThreadLocal 采用了“空间换时间”的方式。

ThreadLocal 会为每一个线程提供一个独立的变量副本，从而隔离了多个线程对数据的访问冲突。因为每一个线程都拥有自己的变量副本，从而也就没有必要对该变量进行同步了。ThreadLocal 提供了线程安全的共享对象，在编写多线程代码时，可以把不安全的变量封装进 ThreadLocal。

我们项目中的拦截器里就有这样的逻辑，在我们微服务中，网关进行登录以及鉴权操作，具体的微服务中需要用到token去解析用户信息，我们就在拦截器的preHandler里定义了threadlocal，通过token解析出user的信息，后续controller以及service使用的时候，直接从threadlocal中取出用户信息的，在拦截器的afterCompletion方法中清理threadlocal中的变量，避免变量堆积消耗内存



## SpringMVC

#### 介绍一下springMVC

springmvc是一个视图层框架，通过MVC模型让我们很方便的接收和处理请求和响应。我给你说说他里边的几个核心组件吧

它的核心控制器是DispatcherServlet，他的作用是接收用户请求，然后给用户反馈结果。它的作用相当于一个转发器或中央处理器，控制整个流程的执行，对各个组件进行统一调度，以降低组件之间的耦合性，有利于组件之间的拓展

接着就是处理器映射器（HandlerMapping）：他的作用是根据请求的URL路径，通过注解或者XML配置，寻找匹配的处理器信息

还有就是处理器适配器（HandlerAdapter）：他的作用是根据映射器处理器找到的处理器信息，按照特定执行链路规则执行相关的处理器，返回ModelAndView

最后是视图解析器（ViewResolver）：他就是进行解析操作，通过ModelAndView对象中的View信息将逻辑视图名解析成真正的视图View返回给用户

接下来我给你说下springmvc的执行流程吧

#### 2、springMVC的执行流程

（1）用户发送`请求`至前端控制器 DispatcherServlet；

（2） DispatcherServlet 收到请求后，调用 HandlerMapping 处理器映射器，请求获取 Handle；

（3）处理器映射器根据请求 url 找到具体的处理器，生成处理器对象及处理器拦截器(如果有则生成)一并返回给 DispatcherServlet；

（4）DispatcherServlet 调用 HandlerAdapter 处理器适配器；

（5）HandlerAdapter 经过适配调用 具体处理器(Handler，也叫后端控制器)；

（6）Handler 执行完成返回 ModelAndView；

（7） HandlerAdapter 将 Handler 执 行 结 果 ModelAndView 返 回 给DispatcherServlet；

（8）DispatcherServlet 将 ModelAndView 传给 ViewResolver 视图解析器进行解析；

（9）ViewResolver 解析后返回具体 View；

（10）DispatcherServlet 对 View 进行渲染视图（即将模型数据填充至视图中）

（11）DispatcherServlet `响应`用户。

#### 3、springMVC接收前台参数的几种方式

- 1、如果传递参数的时候，通过ur1拼接的方式，直接拿对象接收即可，或者string、 int
- 2、如果传递参数的时候，传到后台的是js对象，那么必须使用对象接收，并且加@requestBody，使用requestBody之后，传递的参数至少要有一个，并且所有传的参数都要在后台对象里存在
- 3、get的请求方式，所有的参数接收都使用普通对象或者string、int
- 4、在用form表单提交的时候，所有的参数接收都使用普通对象或者string、int

#### 4、springMVC中的常用注解

@RequestMapping：指定类或者方法的请求路径，可以使用method字段指定请求方式

@GetMapping、@PostMapping：规定了请求方式的方法的请求路径

@RequestParam：接收单一参数的

@PathVariable：用于从路径中接收参数的

@CookieValue：用于从cookie中接收参数的

@RequestBody：用于接收js对象的，将js对象转换为Java对象

@ResponseBody：返回json格式数据

@RestController：用在类上，等于@Controller+@ResourceBody两个注解的和，一般在前后端分离的项目中只写接口时经常使用，标明整个类都返回json格式的数据

等等

#### 5、spring如何整合springMVC

简单的说 springMVC在ssm中整合 就是 在 web.xml 里边配置springMVC的核心控制器:DispatcherServlet; 它就是对指定后缀进行拦截;然后在springMVC.xml里边配置扫描器，可以扫描到带@controller注解的这些类，现在用springMVC都是基与注解式开发， 像@service，@Repository @Requestmapping，@responsebody 啦这些注解标签 等等 都是开发时用的，每个注解标签都有自己的作用;它还配置一个视图解析器，主要就是对处理之后的跳转进行统一配置，有页面的路径前缀和文件后缀 ，如果有上传相关的设置，还需要配置上multpart的一些配置，比如单个文件最大的大小，以及最大请求的大小，大致就是这些

## Springboot

### 什么是springboot

SpringBoot是Spring项目中的一个子工程，其实人们把Spring Boot 称为搭建程序的`脚手架`。其最主要作用就是帮我们快速的构建庞大的spring项目，并且尽可能的减少一切xml配置，做到开箱即用，迅速上手，让我们关注与业务而非配置。

### 2、为什么要用springboot

Spring Boot 优点非常多，如： 一、独立运行 Spring Boot而且内嵌了各种servlet容器，Tomcat、Jetty等，现在不再需要打成war包部署到容器中，Spring Boot只要打成一个可执行的 jar包就能独立运行，所有的依赖包都在一个jar包内。 二、简化配置 spring-boot-starter-web启动器自动依赖其他组件，简少了maven的配置。 三、自动配置 Spring Boot能根据当前类路径下的类、jar包来自动配置bean，如添加一个spring-boot-starter-web启动器就能拥有web的功能，无需其他配置。 四、无代码生成和XML配置 Spring Boot配置过程中无代码生成，也无需XML配置文件就能完成所有配置工作，这一切都是借助于条件注解完成的，这也是Spring4.x的核心功能之一。 五、应用监控 Spring Boot提供一系列端点可以监控服务及应用，做健康检测

### 3、springboot有哪些优点

1. 减少开发，测试时间和努力。
2. 使用 JavaConﬁg 有助于避免使用 XML。
3. 避免大量的 Maven 导入和各种版本冲突。
4. 通过提供默认值快速开始开发。
5. 没有单独的 Web 服务器需要。这意味着你不再需要启动 Tomcat，Glassﬁsh或其他任何东西。
6. 需要更少的配置 因为没有 web.xml 文件。只需添加用@ Conﬁguration 注释的类，然后添加用@Bean 注释的方法，Spring 将自动加载对象并像以前一样对其进行管理。您甚至可以将@Autowired 添加到 bean 方法中，以使 Spring 自动装入需要的依赖关系中。
7. 基于环境的配置 使用这些属性，您可以将您正在使用的环境传递到应用程序：-Dspring.proﬁles.active = {enviornment}。在加载主应用程序属性文件后，Spring 将在（application{environment} .properties）中加载后续的应用程序属性文件。

application.yml

 spring.active.profile=dev

application-dev.yml

application-test.yml

application-prod.yml

### 4、Spring Boot 的核心注解是哪个？它主要由哪几个注解组成的？

启动类上面的注解是@SpringBootApplication，它也是 Spring Boot 的核心注解，主要组合包含了以下 3 个注解： @SpringBootConﬁguration：组合了 @Conﬁguration 注解，实现配置文件的功能。 @EnableAutoConﬁguration：打开自动配置的功能，也可以关闭某个自动配置的选项，如关闭数据源自动配置功能：@SpringBootApplication(exclude = { DataSourceAutoConﬁguration.class })。 @ComponentScan：Spring组件扫描，从当前类所在的包以及子包扫描，之外的包扫描不到，所以我们在开发的时候，所有的类都在主类的子包下

### 5、springboot项目有哪几种运行方式

1. 打包用命令或者放到容器中运行
2. 用 Maven/Gradle 插件运行
3. 直接执行 main 方法运行

### 6、如何理解springboot中的starters？

Starters可以理解为启动器，它包含了一系列可以集成到应用里面的依赖包，你可以一站式集成Spring及其他技术，而不需要到处找示例代码和依赖包。如你想使用Spring JPA访问数据库，只要加入springboot-starter-data-jpa启动器依赖就能使用了。Starters包含了许多项目中需要用到的依赖，它们能快速持续的运行，都是一系列得到支持的管理传递性依赖。

### 7、springboot自动配置原理

这个就得从springboot项目的核心注解@SpringbootApplication说起了，这个注解包含了三个注解，其中一个是@EnableAutoConfiguration注解，这个注解主要是开启自动配置的，这个注解会"猜"你将如何配置 spring，前提是你已经添加 了 jar 依赖项，比如项目中引入了 spring-boot-starter-web ，这个包里已经添加 Tomcat 和 SpringMVC，这个注解节就会自动假设您在开发一个 web 应用程序并添加相应的 spring 配置，springboot默认有一个spring-boot-autoconfigure包，大多数常用的第三方的配置都自动集成了，像redis、es等，这里边有一个`META-INF/spring.factories`文件，这里边定义了所有需要加载的bean的全路径，spring会根据反射的原理，创建这些对象，放到IOC容器中，加载时需要的参数，通过JavaConfig的方式加载配置文件中的参数然后创建了对应的对象，这就是自动配置的原理

## Mybatis

#### 介绍一下mybatis，说一下它的优点和缺点是什么？

Mybatis是一个半ORM（对象关系映射）的持久层框架,它内部封装了JDBC，开发时只需要关注SQL语句本身，不需要花费精力去处理加载驱动、创建连接、创建statement等繁杂的过程,使用时直接编写原生态sql。

优点：

1：基于SQL语句编程，相当灵活，不会对应用程序或者数据库的现有设计造成任何影响，SQL写在XML 里，解除sql与程序代码的耦合，便于统一管理，提供XML标签，支持编写动态SQL语句，并可重用；

2：很好的与各种数据库兼容；

3：提供映射标签，支持对象与数据库的ORM字段关系映射，提供对象关系映射标签，支持对象关系组件维护。

4：与JDBC相比，消除了JDBC大量冗余的代码，不需要手动开关连接，能够与Spring很好的集成

缺点：

1：SQL语句的编写工作量较大，尤其当字段多、关联表多时，对开发人员编写SQL语句的功底有一定要求；

2：SQL语句依赖于数据库，导致数据库移植性差，不能随意更换数据库；

#### 2、**MyBatis与Hibernate有哪些不同**？

首先Hibernate是一个完全面向对象的持久层框架，mybatis是一个半自动化的持久层框架。

开发方面： hibernate开发中，sql语句已经被封装，直接可以使用，加快系统开发， Mybatis 属于半自动化，sql需要手工完成，稍微繁琐，但是如果对于庞大复杂的系统项目来说，复杂的sql语句较多，选择hibernate 就不是一个好方案。

sql优化方面：Hibernate 自动生成sql,有些语句较为繁琐，会多消耗一些性能， Mybatis 手动编写sql，可以避免不需要的查询，提高系统性能；

对象管理方面：Hibernate 是完整的对象-关系映射的框架，开发工程中，无需过多关注底层实现，只要去管理对象即可；Mybatis 需要自行管理 映射关系。

缓存方面：Hibernate的二级缓存配置在SessionFactory生成的配置文件中进行详细配置，然后再在具体的表-对象映射中配置是那种缓存，MyBatis的二级缓存配置都是在每个具体的表-对象映射中进行详细配置，这样针对不同的表可以自定义不同的缓存机制。

总之：Mybatis 小巧、方便、高效、简单、直接、半自动化；Hibernate 强大、方便、高效、复杂、间接、全自动化

#### 3、#{}和${}的区别是什么？

`#{}`是预编译处理，`${}`是字符串替换。

Mybatis在处理`#{}`时，会将sql中的`#{}`替换为?号，调用`PreparedStatement`的set方法来赋值；

Mybatis在处理`${}`时，就是把`${}`替换成变量的值。

使用`#{}`可以有效的防止SQL注入，提高系统安全性。

#### 4、当实体类中的属性名和表中的字段名不一样 ，怎么办 ？

第一种方法：通过在查询的sql语句中定义字段名的别名，让字段名的别名和实体类的属性名一致；

第二种方法：通过`<resultMap>`来映射字段名和实体类属性名的一一对应的关系；

第三种方法：在实体类通过@Column注解也可以实现；

#### 5、通常一个Xml映射文件，都会写一个Dao接口与之对应，这个Dao接口的工作原理是什么？Dao接口里的方法，参数不同时，方法能重载吗？

Dao接口即Mapper接口。接口的全限名，就是映射文件中的namespace的值；接口的方法名，就是映射文件中Mapper的Statement的id值；接口方法内的参数，就是传递给sql的参数。

Mapper接口是没有实现类的，当调用接口方法时，接口全限名+方法名拼接字符串作为key值，可唯一定位一个MapperStatement。在Mybatis中，每一个`<select>、<insert>、<update>、<delete>`标签，都会被解析为一个MapperStatement对象。

Mapper接口里的方法，是不能重载的，因为是使用 全限名+方法名 的保存和寻找策略。Mapper 接口的工作原理是JDK动态代理，Mybatis运行时会使用JDK动态代理为Mapper接口生成代理对象proxy，代理对象会拦截接口方法，转而执行MapperStatement所代表的sql，然后将sql执行结果返回。

#### 6、mybatis 如何执行批量插入?

有两种方式，第一种就是普通的xml中insert语句可以写成单条插入，在调用方循环N次;第二种是xml中insert语句写成一次性插入一个N条的list，举例下面的list标签

```
<insert id="insertBatch" >
    insert into person ( <include refid="Base_Column_List" /> ) 
    values 
    <foreach collection="list" item="item" index="index" separator=",">
        (null,#{item.name},#{item.sex},#{item.address})
    </foreach>
</insert>
```

#### 7、mybatis 如何获取自动生成的(主)键值?

insert 方法总是返回一个int值 ，这个值代表的是插入的行数，不是插入返回的主键id值；如果采用自增长策略，自动生成的键值在 insert 方法执行完后可以被设置到传入的参数对象中，需要增加两个属性，usegeneratedkeys=”true” keyproperty=”id”

```
<insert id=”insertname” usegeneratedkeys=”true” keyproperty=”id”>
     insert into names (name) values (#{name})
</insert>
```

#### 8、在mapper中如何传递多个参数?

```
（1）第一种：
//DAO层的函数
Public UserselectUser(String name,String area);  
//对应的xml,#{0}代表接收的是dao层中的第一个参数，#{1}代表dao层中第二参数，更多参数一致往后加即可。
<select id="selectUser"resultMap="BaseResultMap">  
    select *  fromuser_user_t   whereuser_name = #{0} anduser_area=#{1}  
</select>  
 
（2）第二种： 使用 @param 注解:
public interface usermapper {
   user selectuser(@param(“username”) string username,@param(“hashedpassword”) string hashedpassword);
}
然后,就可以在xml像下面这样使用(推荐封装为一个map,作为单个参数传递给mapper):
<select id=”selectuser” resulttype=”user”>
         select id, username, hashedpassword
         from some_table
         where username = #{username}
         and hashedpassword = #{hashedpassword}
```

#### 9、Mybatis有哪些动态sql？

Mybatis动态sql可以在Xml映射文件内，以标签的形式编写动态sql，执行原理是根据表达式的值 完成逻辑判断并动态拼接sql的功能。Mybatis提供了9种动态sql标签：`trim | where | set | foreach | if | choose | when | otherwise | bind`

#### 10、Xml映射文件中，除了常见的select|insert|updae|delete标签之外，还有哪些标签？

`<resultMap>、<parameterMap>、<sql>、<include>、<selectKey>`，加上动态sql的9个标签，其中`<sql>`为sql片段标签，通过`<include>`标签引入sql片段，`<selectKey>`为不支持自增的主键生成策略标签。

#### 11、Mybatis的Xml映射文件中，不同的Xml映射文件，id是否可以重复？

不同的Xml映射文件，如果配置了namespace，那么id可以重复；如果没有配置namespace，那么id不能重复；

原因就是namespace+id是作为Map<String, MapperStatement>的key使用的，如果没有namespace，就剩下id，那么，id重复会导致数据互相覆盖。有了namespace，自然id就可以重复，namespace不同，namespace+id自然也就不同。

但是，在以前的Mybatis版本的namespace是可选的，不过新版本的namespace已经是必须的了。

#### 12、Mybatis的一级、二级缓存？

一级缓存: 基于 PerpetualCache 的 HashMap 本地缓存，其存储作用域为 Session，当 Session flush 或 close 之后，该 Session 中的所有 Cache 就将清空，默认打开一级缓存。

二级缓存与一级缓存其机制相同，默认也是采用 PerpetualCache，HashMap 存储，不同在于其存储作用域为 Mapper(Namespace)，并且可自定义存储源，如 Ehcache。默认不打开二级缓存，要开启二级缓存，使用二级缓存属性类需要实现Serializable序列化接口(可用来保存对象的状态),可在它的映射文件中配置`<cache/>`

对于缓存数据更新机制，当某一个作用域(一级缓存 Session/二级缓存Namespaces)的进行了C/U/D 操作后，默认该作用域下所有 select 中的缓存将被 clear 掉并重新更新，如果开启了二级缓存，则只根据配置判断是否刷新。

#### 13、使用MyBatis的mapper接口调用时有哪些要求？

1：Mapper接口方法名和mapper.xml中定义的每个sql的id相同； 2：Mapper接口方法的输入参数类型和mapper.xml中定义的每个sql 的parameterType的类型相同； 3：Mapper接口方法的输出参数类型和mapper.xml中定义的每个sql的resultType的类型相同； 4：Mapper.xml文件中的namespace即是mapper接口的类路径。

#### 14、mybatis plus 了解过么？和mybatis有啥区别？

Mybatis-Plus是一个Mybatis的增强工具，它在Mybatis的基础上只做增强，却不做改变。我们在使用Mybatis-Plus之后既可以使用Mybatis-Plus的特有功能，又能够正常使用Mybatis的原生功能。Mybatis-Plus(简称MP)是为简化开发、提高开发效率而生，自带通用mapper的单表操作。

#### 15、MyBatis框架及原理？

MyBatis 是支持定制化 SQL、存储过程以及高级映射的优秀的持久层框架，其主要就完成2件事情：

1. 封装JDBC操作
2. 利用反射打通Java类与SQL语句之间的相互转换

MyBatis的主要设计目的就是让我们对执行SQL语句时对输入输出的数据管理更加方便，所以方便地写出SQL和方便地获取SQL的执行结果才是MyBatis的核心竞争力；

他的执行流程包括

1.读取配置文件，配置文件包含数据库连接信息和Mapper映射文件或者Mapper包路径。

2.有了这些信息就能创建SqlSessionFactory，SqlSessionFactory的生命周期是程序级,程序运行的时候建立起来,程序结束的时候消亡

3.SqlSessionFactory建立SqlSession,目的执行sql语句，SqlSession是过程级,一个方法中建立,方法结束应该关闭

4.当用户使用mapper.xml文件中配置的的方法时，mybatis首先会解析sql动态标签为对应数据库sql语句的形式，并将其封装进MapperStatement对象，然后通过executor将sql注入数据库执行，并返回结果。

5.将返回的结果通过映射，包装成java对象。



## MySQL

####  1、解释一下单列索引和联合索引

单列索引是指在表的某一列上创建索引，联合索引是在多个列上联合创建索引。单列索引可以出现在where条件的任何位置，而联合索引需要按照一定的顺序来写。在多条件查询的时候，联合索引的效率更高，我们联合索引也最多创建两列。

我们创建索引的时候也得考虑到我们这张表的更新频率，如果表里索引比较多的话是比较影响更新速度的，因为创建索引的过程其实就是构建一个二叉树，而每次更新完数据都得重新计算二叉树，所以就影响更新速度。

索引并不是时时都会生效的，比如以下几种情况就能导致索引失效：

- 如果条件中有or，即使其中有条件带索引也不会使用，这也是为什么尽量少用or的原因，如果要想使用or，又想让索引生效，只能将or条件中的每个列都加上索引
- like查询是以%开头，会导致索引失效
- 如果列类型是字符串，那一定要在条件中将数据使用引号引用起来，否则索引失效
- 如果mysql估计使用全表扫描要比使用索引快，则不使用索引

所以呢，我们创建索引的话，也不是随便创建的，我给您说下一些常用的创建索引的原则吧（接着背第四题）

#### 2、使用索引查询的优缺点

使用索引优点第一：可以保证数据库表中每一行的数据的唯一性，第二：可以大大加快数据的索引速度，在使用分组和排序语句

进行数据检索时，同样可以显著减少查询中分组和排序的时间；

缺点：创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加

#### 3、mysql存储引擎都有哪些，有什么区别

我了解到的数据库搜索引擎有MyISAM、InnoDB、BDB、MEMORY等，对于 MySQL 5.5 及更高版本，默认的存储引擎是 InnoDB。在 5.5 版本之前，MySQL 的默认存储引擎是 MyISAM，我主要给您介绍下这两个的区别吧

- InnoDB 存储引擎：

  - 支持自增长列（auto_increment），自增长列的值不能为空，如果在使用的时候为空的话就会从现有的最大值自动+1，如果有但是比现在的还大，则就保存这个值。
  - 支持外键（foreign key），外键所在的表称为子表而所依赖的表称为父表。
  - 支持事务，回滚以及系统崩溃的修复能力，并且支持多版本并发控制的事务安全。
  - 支持mvcc（多版本并发控制）的行级锁，就是通过多版本控制来实现的乐观锁
  - 索引使用的是B+Tree

  优缺点：InnoDB的优势在于提供了良好的事务处理、崩溃修复能力和并发控制。缺点是读写效率较差，占用的数据空间相对较大。

- MyISAM 存储引擎

  不支持事务、支持表级锁

  支持全文搜索

  缓冲池只缓存索引文件，

  不缓存数据文件 MyISAM 存储引擎表由 数据文件（MYD）和索引文件（ MYI）组成

我们项目中常用到的是innoDB，InnoDB存储引擎提供了具有提交、回滚和崩溃恢复能力的事务安全，但是对比Myisam的存储引擎InnoDB写的处理效率差一些并且会占用更多的磁盘空间以保留数据和索引。

#### 4、创建索引的原则

- 经常需要搜索的列上建立索引，可以加快搜索的速度。
- 在作为主键的列上创建索引，强制该列的唯一性，并组织表中数据的排列结构。
- 在经常使用表连接的列上创建索引，这些列主要是一些外键，可以加快表连接的速 度。
- 在经常需要根据范围进行搜索的列上创建索引，因为索引已经排序，所以其指定的 范围是连续的。
- 在经常需要排序的列上创建索引，因为索引已经排序，所以查询时可以利用索引的 排序，加快排序查询。
- 在经常使用 WHERE 语句的列上创建索引，加快条件的判断速度。

#### 5、如何查看查询语句索引是否生效

使用 explain 执行计划查看 在sql前面加入关键字explain 查询出的结果查看type类型检查是否有执行索引

举例：EXPLAIN select * from table where id=2;我们一般优化sql语句的话，type级别都要至少达到ref级别，就是每次查询必须要使用索引

- explain之后返回的列

| 列              | 说明                                                         |
| --------------- | ------------------------------------------------------------ |
| `id`            | 在一个大的查询语句中每个`SELECT`关键字都对应一个唯一的`id`   |
| `select_type`   | SIMPLE（simple）：简单SELECT(不使用UNION或子查询)。 PRIMARY（primary）：子查询中最外层查询，查询中若包含任何复杂的子部分，最外层的select被标记为PRIMARY。 UNION（union）：UNION中的第二个或后面的SELECT语句。 DEPENDENT UNION（dependent union）：UNION中的第二个或后面的SELECT语句,取决于外面的查询。 UNION RESULT（union result）：UNION的结果，union语句中第二个select开始后面所有select。 SUBQUERY（subquery）：子查询中的第一个SELECT，结果不依赖于外部查询。 DEPENDENT SUBQUERY（dependent subquery）：子查询中的第一个SELECT，依赖于外部查询。 DERIVED（derived）：派生表的SELECT (FROM子句的子查询)。 UNCACHEABLE SUBQUERY（uncacheable subquery）：(一个子查询的结果不能被缓存，必须重新评估外链接的第一行) |
| `table`         | 表名                                                         |
| `partitions`    | 匹配的分区信息                                               |
| `type`          | 针对单表的访问方法，参考下面的说明                           |
| `possible_keys` | 可能用到的索引                                               |
| `key`           | 实际上使用的索引                                             |
| `key_len`       | 实际使用到的索引长度                                         |
| `ref`           | 当使用索引列等值查询时，与索引列进行等值匹配的对象信息       |
| `rows`          | 预估的需要读取的记录条数                                     |
| `filtered`      | 某个表经过搜索条件过滤后剩余记录条数的百分比                 |
| `Extra`         | 一些额外的信息                                               |

- type说明

| 类型   | 说明                                                         |
| ------ | ------------------------------------------------------------ |
| All    | 最坏的情况,全表扫描                                          |
| index  | 和全表扫描一样。只是扫描表的时候按照索引次序进行而不是行。主要优点就是避免了排序, 但是开销仍然非常大。如在Extra列看到Using index，说明正在使用覆盖索引，只扫描索引的数据，它比按索引次序全表扫描的开销要小很多 |
| range  | 范围扫描，一个有限制的索引扫描。key 列显示使用了哪个索引。当使用=、 <>、>、>=、<、<=、IS NULL、<=>、BETWEEN 或者 IN 操作符,用常量比较关键字列时,可以使用 range |
| ref    | 一种索引访问，它返回所有匹配某个单个值的行。此类索引访问只有当使用非唯一性索引或唯一性索引非唯一性前缀时才会发生。这个类型跟eq_ref不同的是，它用在关联操作只使用了索引的最左前缀，或者索引不是UNIQUE和PRIMARY KEY。ref可以用于使用=或<=>操作符的带索引的列。 |
| eq_ref | 最多只返回一条符合条件的记录。使用唯一性索引或主键查找时会发生 （高效） |
| const  | 当确定最多只会有一行匹配的时候，MySQL优化器会在查询前读取它而且只读取一次，因此非常快。当主键放入where子句时，mysql把这个查询转为一个常量（高效） |
| system | 这是const连接类型的一种特例，表仅有一行满足条件。            |
| Null   | 意味说mysql能在优化阶段分解查询语句，在执行阶段甚至用不到访问表或索引（高效） |

#### 6、有没有做过数据库建模，自己是设计表和模块

> 一个有三年工作经验的人，一定要说设计过，(实际工作经验的程序员：在系统设计、需求文档，数据建模都应该有所涉及)

数据库建模就是使用PowerDesigner工具，先分析项目需求，前端先出相应的原型，根据原型，我开始做相应的表，设计初期的时候表会有些小浮动修改等，再根据需求设计详细字段。如果后期客户需求改变时，表结构后期跟着调整，就是这样使用工具不断完善过程就是建模，不过一些小的项目的话，简单的通过Navicat里的模型工具就可以实现了

#### 7、左连接、右连接、内连接的区别

内连接的话，就是两表关联的数据才能查出来，关联不到的就查询不到。左连接就是以左表为主，左表数据全查，右表数据没有就显示null，右连接相反

我给您举个例子吧，比如员工和部门表，如果要查询出每个员工的信息以及他的部门信息，那么这个时候用内连接最合适。如果要查询出每个部门下对应的员工信息，那么就需要以部门表为左表，进行左连接查询。这样的话，没有员工的部门也可以被查询出来。

#### 8、 count(1)和count(*) 有什么区别

从执行结果来看count(*)和count(1)没有区别，因为他们都不过滤空值

从执行效率来看MySQL会对count（*）做优化

（1）如果列为主键，count(列名)效率优于count(1)

（2）如果列不为主键，count(1)效率优于count(列名)

（3）如果表中存在主键，count(主键列名)效率最优

（4）如果表中只有一列，则count(*)效率最优

#### 9、mysql查询语句的优化？

- 对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及 的列上建立索引。

- 应尽量避免在 where 子句中使用!=或<>操作符，否则引擎将放弃使用索引而进行 全表扫描。

- 应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用 索引而进行全表扫描，如： `select id from t where num is null` 可以在 num 上设置默认值 0，确保表中 num 列没有 null 值，然后这样查询:`select id from t where num=0`

- 应尽量避免在 where 子句中使用 or 来连接条件，否则将导致引擎放弃使用索引 而进行全表扫描，如： `select id from t where num=10 or num=20` ，可以使用可以这样查询： `select id from t where num=10 union all select id from t where num=20`

- 以%开头的模糊查询也会导致全表扫描： `select id from t where name like '%abc%' `，如果要提高效率的话，可以考虑全文检索来解决。

- in 和 not in 也要慎用，否则会导致全表扫描，如： `select id from t where num in(1,2,3)` 对于连续的数值，能用 between 就不要用 in 了： `select id from t where num between 1 and 3`

- 应尽量避免在 where 子句中对字段进行表达式操作，这将导致放弃使用索引 而进行全表扫描。如：`select id from t where num/2=100 `应改为: `select id from t where num=100*2`

- 应尽量避免在 where 子句中对字段进行函数操作，这将导致引擎放弃使用索引而 进行全表扫描。

  比如说查询name以abc开头的数据： `select id from t where substring(name,1,3)='abc'` ，可以改为`select id from t where name like 'abc%'`

- 不要在 where 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系 统将可能无法正确使用索引。

- 在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中 的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用，并且应尽可 能的让字段顺序与索引顺序相一致。

- 很多时候用 exists 代替 in 是一个好的选择： `select num from a where num in(select num from b) `用下面的语句替换： `select num from a where exists(select 1 from b where num=a.num)`

- 并不是所有索引对查询都有效，SQL 是根据表中数据来进行查询优化的，当索引 列有大量数据重复时，SQL 查询可能不会去利用索引，如一表中有字段 sex，男、女的值 几乎各一半，那么即使在 sex 上建了索引也对查询效率起不了作用。

- 索引并不是越多越好，索引固然可以提高相应的 select 的效率，但同时也降低 了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引，所以怎样建索 引需要慎重考虑，视具体情况而定。一个表的索引数最好不要超过 6 个

#### 10、mysql批量插入5000条数据如何优化？

- 第一种方法：

合并sql插入语句，合并后日志量减少，降低日志刷盘的数据量和频率，从而提高效率，通过合并SQL语句，

同时也能减少SQL语句解析的次数，减少网络传输的IO

比如：`INSERT INTO table(uid,content, type) VALUES ('userid_0', 'content_0', 0);`

改为：

```
INSERT INTO table (uid,content, type) VALUES ('userid_0', 'content_0', 0), ('userid_1','content_1', 1);
```

- 第二种方法：

在同一个事务中进行插入处理

这是因为进行一个INSERT操作时，MySQL内部会建立一个事务，在事务内才进行真正插入处理操作。通过使用同一个事务可以减少创建事务所消耗的时间，所有插入都在执行后才统一进行提交操作。

#### 11、mysql查询重复数据？

比如A表有字段id，pid，sname，

查询重复数据：select * from A

where pid in (select pid from A group by pid having count(pid) > 1);

#### 12、了解过MySQL存储过程和视图吗，介绍一下

- 存储过程

存储程序是被存储在服务器中的组合SQL语句，经过创建编译并保存在数据库中，用户可通过存储过程的名字调用执行。存储过程核心思想就是数据库SQL语言层面的封装与复用。使用存储过程可以较少应对系统的业务复杂性，但是会增加数据库服务器系统的负荷，所以在使用的时候需要综合业务考虑。

对应存储过程的名字使用call调用 ，把对应的参数传递进去，输出参数使用@声明

> 基本语法，了解熟悉一下

```
-- 创建存储过程

DROP PROCEDURE IF EXISTS p01_discount;  //如果存在先删掉再创建 

CREATE PROCEDURE p01_discount(IN consume NUMERIC(5,2),OUT payfee NUMERIC(5,2)) //声明存储过程，in输入参数  out输出参数

BEGIN

       --判断收费方式

       IF(consume>100.00AND consume<=300.00) THEN

              SET payfee=consume*0.8;

       ELSEIF(consume>300.00) THEN 

              SET payfee=consume*0.6;

       ELSE

              SET payfee = consume;

       END IF;

       SELECT payfee AS result;

END ;

-- 调用存储过程

CALL p01_discount(100.0,@discount); 
```

- 视图

视图本身是一张虚拟表，不存放任何数据。在使用SQL语句访问视图的时候，获取的数据是MySQL从其它表中生成的，视图和表在同一个命名空间（因为表和视图共享数据库中相同的名称空间，因此，数据库不能包含具有相同名称的表和视图）。视图查询数据相对安全，视图可以隐藏一些数据和结构，只让用户看见权限内的数据，使复杂的查询易于理解和使用。

原来我们公司做过一个项目的时候，用的是5张表的联查，然后用sql语句来写的话，比较慢，比较麻烦，然后我们把这5张表的联查创建了一个视图，然后就直接查找的是视图，查询速度快，这个视图就是只能做查询，而不能做增删改操作

> 基本语法，了解熟悉一下

```
-- 创建视图

CREATE OR REPLACE VIEW user_order_view AS 

SELECT

       t1.id,t1.user_name,t2.order_no,t2.good_id,

       t2.good_name,t2.num,t2.total_price

FROM v01_user t1

LEFT JOIN v02_order t2 ON t2.user_id =t1.id;

-- 视图调用

SELECT * FROM user_order_view WHERE user_name='Cicada';
```

#### 13、where和having的区别

这两个都是添加查询条件用的。where的话就是拼接普通字段的查询条件，having后边跟上聚合之后数据的查询条件。

比如计算平均薪资在10k以上的部门信息，这会儿的话就要用`select xx from table group by deptId having avg(salary)>10000`

常用的聚合函数有：count、sum、avg、min、max

#### 14、数据库三范式介绍一下

第一范式，原子性，列或者字段不能再分

第二范式的话要满足第一范式，并且不可以把多种数据保存在同一张表中，即一张表只能保存一类数据，否则可能导致插入数据异常。

第三范式，直接性，不存在传递依赖，他要在满足第二范式的条件上，在每一列都和主键直接相关，而不能间接相关。

#### 15、select语句的执行顺序

from--->where--->group by--->having--->计算所有的表达式--->order by-- ->select 输出

大致上是这么个顺序，如果sql里有子查询的话，也会按照这个方式来执行的

#### 16、mysql分库分表介绍下

分库分表的话，是解决MySQL数据量多了之后，单表单库存储量多了之后查询效率低下等问题的，主要分为两种方式，一个是水平拆分，另一个是垂直拆分

垂直拆分的话就是单个表中比如30个字段，拆分为两个表，一个表20个字段，一个表10个字段这样，或者按照其他方式拆分成3个表，这样的拆分原则呢就是将大字段或者不经常修改的或者经常查询的字段拆分出来，作为单独的表存储，然后跟主表一对一的关系存储，这样的话水平扩展了表，并且对功能也做了分离，高并发场景下，垂直拆分一定程度的提升IO性能，不过依然存在单表数据量过大的问题

水平拆分的话就是按照数据量来拆分，比如我们的表里，每个表最多存储200W条数据，然后每个表命名方式为user_0001、user_0002的方式，在查询的时候，用逻辑代码来控制数据查询。这样的话不存在单表单库数据量过大、高并发的性能瓶颈，提升系统稳定性和负载能力。不过水平拆分会导致跨分片的事务一致性难以保证，跨库的join关联查询性能较差，要根据具体的业务来判断具体适用那种分表方式

我们都是结合读写分离和mysql集群做的，读写分离以及集群的话，读写分离话保证了数据的安全性，集群的话其实就相当于水平拆分。这个我们项目中使用MyCat来做的,在mycat里配置好主库和从库,做增删改的时候是对主库进行操作,查询的时候是对从库进行操作,其实mysql本身从5.6以后的版本就带主从复制的功能了,他们是利用mysql里的log文件进行的数据同步

## Redis

#### 介绍一下redis

Redis是一个非关系数据库，我们项目中主要用它来存储热点数据的，减轻数据库的压力，单线程纯内存操作，采用了非阻塞IO多路复用机制，就是单线程监听，我们项目中使用springdata-redis来操作redis

我们项目中使用redis的地方很多，比方说首页的热点数据，数据字典里的数据等都用热地说存储来提高访问速度

redis呢有5种数据类型，string、list、hash、set、zset，我们常用的有string、list和hash，一些简单的key-value类型的都存储在string类型中，比如一些系统开关之类的，是否开放注册等，还有一些存储在hash中，比如我们的首页的推荐数据和热门数据，都是用hash来存储的，一个固定的字符串作为key，每条数据的id作为field，对应的数据作为value存储

redis还有两种持久化方式，一个是RDB，这也是redis默认的持久化方式，这种方式是以快照的方式存储数据，在固定的时间段内如果有多少变化，那么就会生成快照存储到磁盘上，redis 在进行数据持久化的过程中，会先将数据写入到一个临时文件中，待持久化过程都结束了，才会用这个临时文件替换上次持久化好的文件。正是这种特性，让我们可以随时来进行备份，因为快照文件总是完整可用的。对于 RDB 方式，redis 会单独创建一个子进程来进行持久化，而主进程是不会进行任何 IO 操作的，这样就确保了 redis 极高的性能。 这种方式的优点呢就是快，但是如果没等到持久化开始redis宕机了，那么就会造成数据丢失

还有一种是AOF，是即时性的持久化方式，是将 redis 执行过的所有写指令记录下来，在下次 redis 重新启动时，只要把这些写指令从前到后再重复执行一遍，就可以实现数据恢复了。AOF的方式会导致性能下降

两种方式可以同时开启，当两种方式同时开启时，数据恢复Redis会优先选择AOF恢复。

我们项目中使用的持久化方式就是默认的RDB，因为我们存储的数据首先来说不是很重要的数据，如果丢失了，还可以从数据库加载到，主要用的就是性能这块

#### 2、redis缓存雪崩和缓存穿透、缓存预热、缓存降级

- 缓存雪崩

我们可以简单的理解为：由于原有缓存失效，新缓存还没有存入到redis的期间

比方说：我们设置缓存时采用了相同的过期时间，在同一时刻出现大面积的缓存过期，所有原本应该访问缓存的请求都去查询数据库了，而对数据库CPU和内存造成巨大压力，严重的会造成数据库宕机。从而形成一系列连锁反应，造成整个系统崩溃。

解决办法：

加最多的解决方案就是锁，或者队列的方式来保证不会有大量的线程对数据库一次性进行读写，从而避免失效时大量的并发请求落到底层存储系统上。还有一个简单方案就是缓存失效时间分散开，不设置固定的实效时间，采用随机失效的策略来解决

- 缓存穿透：

缓存穿透是指用户查询数据，在数据库没有，自然在缓存中也不会有。这样就导致用户查询的时候，在缓存中找不到，每次都要去数据库再查询一遍，然后返回空，这就相当于进行了两次无用的查询。像这样请求就绕过缓存直接查数据库，这也是经常提的缓存命中率问题

解决办法

最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。另外也有一个更为简单粗暴的方法，如果一个查询返回的数据为空，不管是数据不存在，还是系统故障，我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。

- 缓存预热：

缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题！用户直接查询事先被预热的缓存数据！

操作方式：

1、直接写个缓存刷新页面，上线时手工操作下；

2、数据量不大，可以在项目启动的时候自动进行加载；

然后就是缓存更新：

1、定时去清理过期的缓存；

2.、当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存

- 缓存降级：

当访问量剧增、服务出现问题，比如响应时间慢或不响应，或者非核心服务影响到核心流程的性能时，仍然需要保证服务还是可用的，即使是有问题的服务。redis可以帮助系统实现数据降级载体，系统可以根据一些关键数据进行自动降级，也可以配置开关实现人工降级。降级的最终目的是保证核心服务可用，即使是有损的。

#### 3、redis分布式锁

这个分布式锁这里，我们原来传统的项目都在单台服务器上部署用java里的锁synchronized这个同步锁就行，但是他这个是针对对象的锁，但是我们分布式的项目需要把项目部署到多台服务器上，每台服务器的对象都不同，所以就得考虑用分布式锁，这块实现起来也比较简单，其实这个锁就是redis中的一个key-value的一对值，在使用的时候吧，首先使用setnx方法进行尝试加锁，并可以设置过期时间，如果返回1则代表加锁成功，然后立即对这个锁设置一个实效时间，防止服务宕机，锁一致存在，在处理完业务逻辑之后，删除锁就行了，其他线程就可以获取锁进行业务了

#### 4、redis主从复制

通过持久化功能，Redis保证了即使在服务器重启的情况下也不会损失（或少量损失）数据，因为持久化会把内存中数据保存到硬盘上，重启会从硬盘上加载数据。但是由于数据是存储在一台服务器上的，如果这台服务器出现硬盘故障等问题，也会导致数据丢失。为了避免单点故障，通常的做法是将数据库复制多个副本以部署在不同的服务器上，这样即使有一台服务器出现故障，其他服务器依然可以继续提供服务。为此， Redis 提供了复制功能，可以实现当一台数据库中的数据更新后，自动将更新的数据同步到其他数据库上。

Redis的主从结构可以采用一主多从或者级联结构，Redis主从复制可以根据是否是全量分为全量同步和增量同步，配置非常简单，只需要在从节点配置`slave of`主节点的ip即可，如果有密码，还需要配置上密码，从节点只能读数据，不能写数据

全量同步主要发生在初次同步的时候，大概的步骤是

- 从服务器连接主服务器，发送SYNC命令；
- 主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令；
- 主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令；
- 从服务器收到快照文件后丢弃所有旧数据，载入收到的快照；
- 主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令；
- 从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令；

还有就是增量同步，主要发生在redis的工作过程中，Slave初始化后开始正常工作时主服务器发生的写操作同步到从服务器的过程。 增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令。

#### 5、redis集群

Redis本身就支持集群操作redis_cluster，集群至少需要3主3从，且每个实例使用不同的配置文件，主从不用配置，集群会自己选举主数据库和从数据库，为了保证选举过程最后能选出leader，就一定不能出现两台机器得票相同的僵局，所以一般的，要求集群的server数量一定要是奇数，也就是2n+1台，并且，如果集群出现问题，其中存活的机器必须大于n+1台，否则leader无法获得多数server的支持，系统就自动挂掉。所以一般是3个或者3个以上的奇数节点。

Redis 2.8中提供了哨兵工具来实现自动化的系统监控和故障恢复功能。哨兵的作用就是监控redis主、从数据库是否正常运行，主数据库出现故障自动将从数据库转换为主数据库

我们公司搭建的redis集群是用的ruby脚本配合搭建的，我们一共搭建了6台服务器，3主3备，他们之间通信的原理是有一个乒乓协议进行通信的，我再给你说下一他们往里存储数据的机制吧，其实这个redis搭建好集群以后每个节点都存放着一个hash槽，每次往里存储数据的时候，redis都会根据存储进来的key值算出一个hash值，通过这个hash值可以判断到底应该存储到哪一个哈希槽中，取的时候也是这么取的，这就是我了解的redis集群

#### 6、除了redis，还了解哪些别的非关系型数据库

有memacache，MongoDB这些，以及redis这几个都是非关系型数据库

memacache是纯内存型的，只支持简单的字符串数据，并且value值最大只能是1MB，而且所有的数据都只能存储在内存中，如果服务宕机或者关机重启，数据就会丢失，没有持久化功能

MongoDB的话是存储的数据都在磁盘上，功能比较多，不过性能没有其他两种好

而redis呢，支持的数据类型比较多，而且速度也非常快，value最大可以支持到512MB，而且既可以把数据存储在内存里，也可以持久化到磁盘上，重启之后还可以把磁盘中的数据重新加载到内存里，从性能以及数据安全上来说，都比memacache和MongoDB好一些

#### 7、redis数据同步

这一块主要是跟mysql数据同步吧，mysql数据可能会发生变动，那么redis就要跟数据库的数据保持一致我们实际去使用的时候，是在数据发生变动的地方，比如增删改的时候，新奇一个线程，然后将变动的数据更新到redis中，根据不同的场景需求，也可以在数据变动时，把redis里的数据删掉，下一次用户查询的时候，发现redis中没有数据，就会重新去数据库加载一遍，这样也可以实现同步的效果

#### 8、介绍一下redis的pipeline

pipeline的话，就是可以批量执行请求的命令

我们都知道redis是单线程的，在执行命令的时候，其他客户端是阻塞状态的，如果在高并发的时候，其实是会影响一定效率的，所以redis提供了pipeline，可以让我们批量执行命令，大大的减少了IO阻塞以及访问效率

因为pipeline是批量执行命令，我们一般会结合redis的事物去使用，它也符合事务的ACID特性，**MULTI**开启事物，**EXEC**执行，**DISCARD**清除事物状态，回到非事物状态，在使用前，还可以结合**WATCH**监控来使用，如果我们在执行一组命令的过程中，不想让其中的某个值被其他客户端改动，就可以使用**WATCH**，使用了之后，如果被改动，事务会自动回滚，可以很好的保证我们批量执行命令的时候，数据的准确性，在使用完成之后，可以使用**UNWATCH**解除监控。

#### 9、介绍下redis中key的过期策略

定时删除：在设置key的过期时间的同时，为该key创建一个定时器，让定时器在key的过期时间来临时，对key进行删除

惰性删除：key过期的时候不删除，每次从数据库获取key的时候去检查是否过期，若过期，则删除，返回null

定期删除：每隔一段时间执行一次删除过期key操作

redis 过期策略是：定期删除+惰性删除。

所谓定期删除，指的是 redis 默认是每隔 100ms 就随机抽取一些设置了过期时间的 key，检查其是否过期，如果过期就删除。



### 缓存问题

#### 读模式

```markdown
缓存穿透
	查询一个null数据。解决方法：缓存空数据
缓存击穿
	大量并发进来同时查询一个正好过期的数据
缓存雪崩
	
```









## 计算机网络



从浏览器输入www.baidu.com之后，会将请求发送给DNS服务器，DNS服务器解析域名返回一个ip地址。此时浏览器所在ip地址和DNS那边返回的ip地址都要和子网掩码做与运算255.255.255.0。如果不是一个子网下面，http请求将被打包成数据包。





### TCP连接

三次握手，四次挥手

第一次握手，发送一个请求报文tcp数据包，尝试建立连接。然后服务器端返回一个确认报文，这是第二次握手。第三次握手，客户端发送一个复位请求报文，确保，服务器端只有一次连接。如果没有第三次握手的话，如果客户端第一次握手有卡在中途，后面又成功发送了，那么服务器还是会开辟一块资源来建立连接。







## 面经

### 孩子王

第一次实习面试，一面：

介绍自己

为什么选择Java

学了这么久自动化，现在转行，不觉得可惜吗？

知道哪些设计模型

创建多线程的方式

写一个sql

